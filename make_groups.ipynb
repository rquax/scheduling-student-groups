{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import groups\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = op.join(\"data\", \"Balance of skills CSS 2024(1-83).xlsx\")\n",
    "\n",
    "assert op.exists(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here, define all column names (take them from opening the Excel and copy/paste)\n",
    "\n",
    "col_name = 'Name2'\n",
    "col_email = 'E-mail address'\n",
    "\n",
    "cols_skills = ['Programming skills2', 'Domain-specific knowledge/skills']\n",
    "\n",
    "# should also be read from the file and stored in the dataframe, to be used later or at least included in the output of the group assignment\n",
    "cols_extra = ['What is your (BSc) background? (E.g., informatics, psychobiology, ...)', \n",
    "              'Do you know what topic you\\'d like to work in, if you had the choice? (E.g., climate change, financial markets, molecular biology, ...) Mention as many keywords as possible, such as multiple topics...']\n",
    "\n",
    "col_interests = cols_extra[-1]  # this column may be used in the optimization process (textual similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = groups.read_student_records(fn, cols_skills, col_name=col_name, col_email=col_email,\n",
    "                                 col_background=cols_extra[0], \n",
    "                                 col_interests=cols_extra[1], \n",
    "                                 to_replace=[groups._default_skill_replacement, groups._default_application_domain_expertise_replacement], verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find potential duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def text_similarity(a: str, b: str) -> float:\n",
    "    \"\"\"Return a number between 0 and 1 indicating how similar the two given strings are.\"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_similarity_threshold = 0.8  # the higher this number, the more conservative is the filtering of duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sims = []  # list of (name_index1, name_index2, name1, name2, similarity-score)\n",
    "\n",
    "names = df[col_name].to_list()\n",
    "\n",
    "for nix1, row1 in df[[col_name]].iterrows():\n",
    "    name1 = row1[col_name]\n",
    "    for nix2, row2 in df[[col_name]].iterrows():\n",
    "        name2 = row2[col_name]\n",
    "        if nix2 > nix1:  # prevent checking a name pair in both directions\n",
    "            sim = text_similarity(name1, name2)\n",
    "\n",
    "            name_sims.append((nix1, nix2, name1, name2, sim))\n",
    "\n",
    "name_sims = list(sorted(name_sims, key=lambda tup: tup[-1], reverse=True))\n",
    "\n",
    "# all name pairs that are very similar (also some pairs below the `name_similarity_threshold` so one can eyeball what a good threshold would actually be):\n",
    "[n for n in name_sims if n[-1] > 0.8 * name_similarity_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## actually REMOVE the duplicate names (always remove the earlier occurrence)\n",
    "\n",
    "for nix1, nix2, name1, name2, sim in name_sims:\n",
    "    if sim > name_similarity_threshold:\n",
    "        if nix1 in df.index:\n",
    "            df.drop(nix1, axis='index', inplace=True)\n",
    "            print(f'Removed row with index={nix1}, which had {col_name}={name1}, because it was too similar to index={nix2}, {col_name}={name2} (similarity: {sim})')\n",
    "        else:\n",
    "            print(f'Did not remove row with index={nix1} because it no longer existed in the dataframe')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Will make groups with {len(df)} people.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a heatmap of the programming skills versys domain expertise\n",
    "sns.heatmap(pd.crosstab(df[cols_skills[0]], df[cols_skills[1]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_target_group_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sizes = groups.infer_group_size_array(len(df), _target_group_size)\n",
    "\n",
    "print(len(group_sizes))\n",
    "\n",
    "group_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an optimization of group compositions based on balancing the skills as well as aligning the interests \n",
    "# (may take 1-15 minutes; e.g. for 82 students it took around 10 minutes for `max_iter=2500`)\n",
    "fitness, group_assignment = groups.optimize_assignment_for_diversity(df, cols_skills, _target_group_size, steepness=(180., 30.), max_iter=3500, max_contig_no_improvements=50, interests_weight=0.5, \n",
    "                                                                     col_interests=col_interests, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convergence plot of the optimization procedure; here you'd want to see that the fitness has sufficiently converged to its maximum value and that no further appreciable\n",
    "# growth can be expected. Otherwise, increase `max_iter` in the above optimization. \n",
    "plt.plot(range(len(groups._fitness_over_epochs)), groups._fitness_over_epochs, '-ok')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Fitness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_assignment  # solution of assignment of student indices (i.e., row numbers in the dataframe) organized into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_label = op.basename(fn)[:op.basename(fn).index('.')].replace(' ', '_').lower()\n",
    "\n",
    "results_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This prints all groups in a simple text (also to file), but this is only insightful for small numbers of students.\n",
    "### It is more meant for completeness, can be removed when this output is made nicer such as in a dataframe/xlsx file.\n",
    "\n",
    "studrowix_to_groupix = dict()\n",
    "\n",
    "for gix, stud_ixs in enumerate(group_assignment):\n",
    "    with open(op.join(output_dir, f'group{gix}_{results_label}.txt'), 'w') as fout:\n",
    "        print(f'\\tGroup {gix}:')\n",
    "\n",
    "        for six in stud_ixs:\n",
    "            studrowix_to_groupix[six] = gix\n",
    "\n",
    "            print(f' - Student (row {six} in data file):\\n{df.loc[six, [col_name, col_email] + cols_extra].to_dict()}')\n",
    "            fout.write(f' - Student (row {six} in data file):\\n{df.loc[six, [col_name, col_email] + cols_extra].to_dict()}'.encode(\"ascii\", \"ignore\").decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df.copy(deep=True)\n",
    "\n",
    "df_out['Group ID'] = [studrowix_to_groupix[six] for six in df_out.index]\n",
    "\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_out_xlsx = op.join(output_dir, f'group_assignment_{results_label}_minimal.xlsx')\n",
    "\n",
    "df_out.to_excel(op.join(output_dir, f'group_assignment_{results_label}.xlsx'))\n",
    "df_out[[col_name, col_email, 'Group ID']].to_excel(fn_out_xlsx)\n",
    "\n",
    "print(f'Results written to {fn_out_xlsx}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can find some names or group compositions and see if you can co-locate some names, or find groups which are not diverse enough, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_which_contain(df, col_name: str, col_val: str):\n",
    "    return df.loc[list(map(lambda name: col_val in name, df[col_name]))]\n",
    "\n",
    "def get_rows_where_equals(df, col_name: str, col_val):\n",
    "    return df.loc[df[col_name] == col_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_rows_which_contain(df_out, 'Name', 'Elizabeth')  # example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rows_where_equals(df_out, 'Group ID', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
